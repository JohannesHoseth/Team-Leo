{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scraping_class\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = 'oscar_winners_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_movies(winners_or_nominees):\n",
    "    \n",
    "    if winners_or_nominees == 'nominees':\n",
    "        set_range = range(1,600,50)\n",
    "    elif winners_or_nominees == 'winners':\n",
    "        set_range = range(1,100, 100)\n",
    "    \n",
    "    connector = scraping_class.Connector(logfile)\n",
    "\n",
    "    movies_data = []\n",
    "    \n",
    "    for i in set_range:\n",
    "        \n",
    "        if winners_or_nominees == 'nominees':        \n",
    "            url = 'https://www.imdb.com/search/title/?groups=oscar_best_picture_nominees&start=%s&ref_=adv_nxt' % str(i)\n",
    "        elif winners_or_nominees == 'winners':\n",
    "            url = 'https://www.imdb.com/search/title/?count=100&groups=oscar_best_picture_winners&sort=year,desc&start=%s&ref_=nv_ch_osc' % str(i)\n",
    "\n",
    "        #response, call_id = connector.get(url, 'get_%s' % winners_or_nominees)\n",
    "        response = requests.get(url, headers={\"Accept-Language\":\"en-US, en;q=0.5\"})\n",
    "        \n",
    "        if response.ok:\n",
    "            data = response.text\n",
    "            soup = BeautifulSoup(data, \"lxml\")\n",
    "            movies = soup.find_all('div', attrs={'lister-item-content'})\n",
    "\n",
    "\n",
    "            for movie in movies:\n",
    "\n",
    "                try:\n",
    "                    runtime = movie.find('p', attrs={'text-muted'}).find('span', attrs={'runtime'}).text\n",
    "                    runtime = int(runtime.split(' ')[0])\n",
    "\n",
    "                    genre   = movie.find('p', attrs={'text-muted'}).find('span', attrs={'genre'}).text.strip().split(', ')\n",
    "\n",
    "\n",
    "                    idx, title, year = movie.find('h3', attrs={'lister-item-header'}).text.strip().split('\\n')\n",
    "                    idx = idx.split('.')[0]\n",
    "                    \n",
    "                    link = movie.find('a')\n",
    "                    link = str(link).split('href=\"')[1].split('\"')[0]\n",
    "                    link  = 'https://www.imdb.com' + link\n",
    "\n",
    "                    try:\n",
    "                        if movie.find_all('span')[-2].text == 'Gross:':\n",
    "                            gross = movie.find_all('span', attrs={'name':'nv'})[-1].text\n",
    "                            gross = float(gross.split('$')[1].split('M')[0])\n",
    "                        else:\n",
    "                            gross = np.nan\n",
    "                    except:\n",
    "                        gross = np.nan\n",
    "\n",
    "                    try:\n",
    "                        metascore = movie.find('span', attrs={'metascore'}).text\n",
    "                    except:\n",
    "                        metascore = np.nan\n",
    "\n",
    "                    job = movie.find_all('p')[2].text\n",
    "\n",
    "                    actors = [i.split('\\n')[1] for i in job.split('Stars:')[1].split(',')]\n",
    "                    directors = [i.split(',')[0] for i in job.split('Stars:')[0].split('Director')[1].split(':\\n')[1].split('\\n')[:-2]]\n",
    "                    \n",
    "                    links_people = [str(i).split('href=\"')[1].split('\"')[0] for i in movie.find_all('p')[2].find_all('a')]\n",
    "                    links_people = [\"https://www.imdb.com/\" + i + \"awards\" for i in links_people]\n",
    "\n",
    "                    try:\n",
    "                        year = year.split('(I')[1]\n",
    "                        try:\n",
    "                            year = year.split('I) (')[1].split(')')[0]\n",
    "                        except:\n",
    "                            year = year.split(') (')[1].split(')')[0]\n",
    "                    except:\n",
    "                        year = year.split('(')[1].split(')')[0]\n",
    "\n",
    "                    movies_data.append([idx, title, year, runtime, genre, metascore, gross, link, directors, actors, links_people])\n",
    "\n",
    "                except:\n",
    "                    NameError\n",
    "\n",
    "        else:\n",
    "            print('Response failed!')\n",
    "\n",
    "    df = pd.DataFrame(movies_data)\n",
    "    df.columns = ['index', 'title', 'year', 'runtime_min', 'genre', 'metascore', 'gross_mil', 'link_movie', 'director', 'actors', 'link_people']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_awards(actorlist):\n",
    "    \n",
    "    connector = scraping_class.Connector(logfile)\n",
    "    \n",
    "    nom = 0\n",
    "    win = 0\n",
    "    \n",
    "    for i in actorlist:\n",
    "        url = str(i)\n",
    "        \n",
    "        #response, call_id = connector.get(url, 'get_awards')\n",
    "        response = requests.get(url, headers={\"Accept-Language\":\"en-US, en;q=0.5\"})\n",
    "        \n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "        table_node = soup.find_all('table', attrs ={'class': 'awards'})\n",
    "\n",
    "        awards_data = []\n",
    "\n",
    "        for i in table_node:\n",
    "            try:\n",
    "                award_year = i.find_all('td', attrs ={'class': 'award_year'})\n",
    "                award_year =[i.find('a').text.strip('\\n') for i in award_year]\n",
    "                outcome = i.find_all('td', attrs = {'class': 'award_outcome'})\n",
    "\n",
    "                outcome = [i.text for i in outcome]\n",
    "\n",
    "                award = [i.split('\\n')[2] for i in outcome]\n",
    "                result = [i.split('\\n')[1] for i in outcome]\n",
    "\n",
    "                if award[0] == 'Oscar':\n",
    "                    awards_data.append([award_year, award, result])\n",
    "            except:\n",
    "                NameError\n",
    "        \n",
    "        if awards_data:\n",
    "            df = pd.DataFrame(awards_data[0]).T\n",
    "\n",
    "            df = df.assign(nom = lambda df: pd.Series.str(df[2])[0:] == 'Nominee')\n",
    "            df = df.assign(win = lambda df: pd.Series.str(df[2])[0:] == 'Winner')\n",
    "\n",
    "\n",
    "            for i in df.nom:\n",
    "                if i == True:\n",
    "                    nom += 1\n",
    "\n",
    "            for i in df.win:\n",
    "                if i == True:\n",
    "                    win += 1\n",
    "    return nom, win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(movie_url):\n",
    "    \n",
    "    #connector = scraping_class.Connector(logfile)\n",
    "\n",
    "    #response, call_id = connector.get(movie_url, 'get_metadata')\n",
    "    response = requests.get(movie_url, headers={\"Accept-Language\":\"en-US, en;q=0.5\"})\n",
    "\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    movie = soup.find_all('div',attrs={'class':'txt-block'})\n",
    "    metadata = {}\n",
    "\n",
    "    for i in movie:\n",
    "        try:\n",
    "            lookup = ['country', 'language', 'color']\n",
    "            lookup2 = ['release date', 'aspect ratio']\n",
    "            valuelist = ['budget', 'cumulative worldwide gross', 'aspect ratio']\n",
    "\n",
    "            headline = i.find('h4').text.lower().split(':')[0]\n",
    "            txtblock = i.text\n",
    "\n",
    "            if headline in lookup:\n",
    "                link_values = i.find('a').text\n",
    "                metadata[headline] = link_values\n",
    "\n",
    "            if headline in lookup2:\n",
    "                values = txtblock.split('\\n')[1].split(':')[1]\n",
    "                try:\n",
    "                    values = values.split('(')[0].strip()\n",
    "                    metadata[headline] = values\n",
    "                except:\n",
    "                    values = float(values.strip())\n",
    "                    metadata[headline] = values\n",
    "\n",
    "            data = txtblock.split(':')[0].strip().lower()\n",
    "            values = txtblock.split(':')[1].split('$')[1].strip().lower()\n",
    "\n",
    "            if data in valuelist:\n",
    "                values = values.replace(',','')\n",
    "\n",
    "                try:\n",
    "                    values = int(values.split('(')[0])\n",
    "                    metadata[data] = values\n",
    "\n",
    "                except:\n",
    "                    values = int(values)\n",
    "                    metadata[data] = values\n",
    "\n",
    "        except:\n",
    "            NameError\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(df):\n",
    "    \n",
    "    genres = []\n",
    "    row = 0\n",
    "\n",
    "    for i in df.genre:\n",
    "        for genre in i:\n",
    "            if genre not in genres:\n",
    "                genres.append(genre)\n",
    "\n",
    "    for genre in genres:\n",
    "        df[genre] = 0\n",
    "\n",
    "    for i in df.genre:\n",
    "        for genre in i:\n",
    "            df[genre][row] = 1\n",
    "        row += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    win_nom = []\n",
    "    \n",
    "    for movie_list in ['winners', 'nominees']:\n",
    "        print('... Initializing \"%s\" scraper ...' %movie_list)\n",
    "        \n",
    "        movies   = get_movies(movie_list)\n",
    "        print('... Movies has been scraped ...')\n",
    "    \n",
    "        awards   = [get_awards(i) for i in movies.link_people]\n",
    "        print('... Awards has been scraped ...')\n",
    "        \n",
    "        metadata = [get_metadata(i) for i in movies.link_movie]\n",
    "        print('... Metadata has been scraped ...')\n",
    "    \n",
    "        awards   = pd.DataFrame(awards, columns=['nom_people_sum', 'won_people_sum'])\n",
    "        metadata = pd.DataFrame(metadata)\n",
    "\n",
    "        df = movies.merge(awards, left_index = True, right_index = True)\n",
    "        df = df.merge(metadata, left_index = True, right_index = True)\n",
    "        \n",
    "        #df = get_genres([df])\n",
    "        #print('... Genre dummies have been created ...')\n",
    "        \n",
    "        df.to_csv('oscar_%s.csv' % movie_list)\n",
    "        print('... CSV file: oscar_%s.csv has been created ...' % movie_list)\n",
    "        \n",
    "        win_nom.append(df)\n",
    "        \n",
    "    return win_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Initializing \"winners\" scraper ...\n",
      "... Movies has been scraped ...\n",
      "... Awards has been scraped ...\n",
      "... Metadata has been scraped ...\n",
      "... CSV file: oscar_winners.csv has been created ...\n",
      "... Initializing \"nominees\" scraper ...\n",
      "... Movies has been scraped ...\n",
      "... Awards has been scraped ...\n",
      "... Metadata has been scraped ...\n",
      "... CSV file: oscar_nominees.csv has been created ...\n"
     ]
    }
   ],
   "source": [
    "win, nom = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = nom.assign(won_oscar = lambda nom: nom.title.isin(win.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() got an unexpected keyword argument 'column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-85272ebb550e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: drop() got an unexpected keyword argument 'column'"
     ]
    }
   ],
   "source": [
    "nom.drop(column='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom.to_csv('oscar_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('oscar_winners.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
